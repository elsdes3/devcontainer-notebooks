[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Multi-Step Dev Containers Workflow",
    "section": "",
    "text": "Run a multi-step Jupyter notebook-based workflow on Ubuntu Desktop, in which each step runs inside its own Dev Container.\nThe following workflow steps are included\n\nretrieve raw data\n\nruns ETL pipeline to retrieve data and store in private cloud storage (AWS S3 bucket)\nsee notebooks/01-get-data\n\nexplore raw data\n\nperforms exploratory data analysis using data stored in private cloud storage (AWS S3 bucket)\nsee notebooks/02-eda\n\n\n\n\n\n\nInstall the Ubuntu desktop operating system\nEnsure Docker (including docker-compose) is installed locally. For detailed instructions on installing Docker on Ubuntu, see the following helpful resources\n\nDocker installation instructions on Ubuntu\nDigital Ocean installation walkthrough on Ubuntu\n\nDownload and install VS Code. Install the VS Code Dev Containers extension.\nCreate an AWS account and provision the following AWS resources\n\ncreate a private S3 bucket\n\nAWS documentation\nSimplified.guide walkthrough\n\ncreate an (Administrator) IAM user with the AdministratorAccess policy or with another policy that permits the user to access the private S3 bucket created above\ncreate access keys for the IAM user\ncopy the Access key ID and Secret Access Key into ~/.aws/credentials\n\n\n\n\n\nClone this repo into the working folder (eg. clone into ~/Downloads) and launch VS Code.\n\n\nUse the following approach to execute a single step of the workflow (01-get-data or 02-eda) inside a container. If the container has not been built, it will first be built before running it.\n\nSelect File &gt; Open Folder… and select the notebooks sub-folder (eg. select ~/Downloads/devcontainer-notebooks/notebooks)\n\ntwo sub-folders (01-get-data and 02-eda) should be visible\neach sub-folder corresponds to a single step in the above workflow\n\nDuring the first build and run of a container, a pop-up appears at the bottom right of the screen indicating the parent directory is detected to be a git repository. It asks if this repository should be opened in the text editor (VS Code)\n\nA git repository was found in the parent folders of the workspace or the open file(s). Would you like to open the repository?\n\nThe parent directory is not required for any analysis inside the container, so this message can be ignored. Click Never.\nPress F1 or Ctrl + Shift + P and select Dev Containers: Open Folder in Container….\nSelect a sub-folder (01-get-data or 02-eda) to run one step of the workflow\n\na container will now be built to run this step\n\n(optional) A pop-up appears at the bottom right of the screen indicating Starting Dev Contiainer (show log). Click Starting Dev Contiainer (show log) to view the container build logs.\n(optional) The TERMINAL shows the logs of the container build process. To view these logs, select TERMINAL &gt; Maximize Panel Size.\n(optional) After the container has been built\n\nthe logs in the TERMINAL will stop updating\nthe lower left remote indicator will display one of\n\nDev Container: Get Data (for the get-data step of the workflow)\nDev Container: Eda (for the eda step)\n\nthe following contents of the workspace will be visible in the File Explorer\n\n.devcontainer\nnotebooks\nsrc\n\n\n(optional) In the terminal, click Restore Panel Size.\nOpen the notebooks folder and launch a notebook\nSelect a Jupyter kernel\n\nfrom the top-right corner, click Select Kernel\n\nselect Python Environments\nselect one of\n\nget-data (Python 3.xx.xx)\neda (Python 3.xx.xx)\n\n\nall the Python libraries listed in the above .devcontainer/environment.yml file for development of this step of the workflow have been installed in this Python environment. After the kernel is selected, all these libraries can be imported into this notebook and all cells in the notebook can be executed without any errors about missing dependencies.\n\n\n\n\n\n\nShut down the container inside which the notebook for the workflow step is running\n\nclose any open notebooks\nclose the connection to the container\n\nclick the lower left remote development indicator\nselect Close Remote Connection\n\n\n\n\n\n\nTo run a container that was previously built locally, follow steps 1 to 9 from above.\n\n\n\n\nRemove any container resources for the workflow step\n\nlaunch a terminal at the root directory of the project (eg. in ~/Downloads)\nclean up containers and images for a single workflow step (get-data or eda)\n ~/Downloads/devcontainer-notebooks$ make reset-&lt;step-name&gt;\n(optional) Remove unused docker resources\n~/Downloads/devcontainer-notebooks$ make docker-system-prune\n\n\n\n\n\n\n\nCode formatting settings specified in .devcontainer/devcontainers.json are being ignored. As a result, Python modules in src are not correctly formatted.\nThis container will support running a Jupyter notebook in VS Code. It will not start the Jupyter Lab interface in a web browser.\nIt was not possible to mount the local ~/.aws folder to the same path inside the container using the docker-compose.yml file. Instead, this mounting was done using the devcontainer.json file.\nThis is an opinionated setup to work with containers inside multiple containers. A separate docker-compose.yml file is used per step of the workflow. An alternate setup to work with multiple Dev Containers (not involving notebooks) is demonstrated here. It has the benefit of using a single docker-compose.yml file that could be adapted to capture all steps of a multi-step notebook-based workflow.\n\n\n\n\n\nAWS documentation to create an IAM user\nVS Code\n\nConfiguring multiple Dev Containers\nDev Containers Playlist\n\nchange a user\nwork with monorepos\nadd (mount) a local folder"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Multi-Step Dev Containers Workflow",
    "section": "",
    "text": "Run a multi-step Jupyter notebook-based workflow on Ubuntu Desktop, in which each step runs inside its own Dev Container.\nThe following workflow steps are included\n\nretrieve raw data\n\nruns ETL pipeline to retrieve data and store in private cloud storage (AWS S3 bucket)\nsee notebooks/01-get-data\n\nexplore raw data\n\nperforms exploratory data analysis using data stored in private cloud storage (AWS S3 bucket)\nsee notebooks/02-eda"
  },
  {
    "objectID": "index.html#pre-requisites",
    "href": "index.html#pre-requisites",
    "title": "Multi-Step Dev Containers Workflow",
    "section": "",
    "text": "Install the Ubuntu desktop operating system\nEnsure Docker (including docker-compose) is installed locally. For detailed instructions on installing Docker on Ubuntu, see the following helpful resources\n\nDocker installation instructions on Ubuntu\nDigital Ocean installation walkthrough on Ubuntu\n\nDownload and install VS Code. Install the VS Code Dev Containers extension.\nCreate an AWS account and provision the following AWS resources\n\ncreate a private S3 bucket\n\nAWS documentation\nSimplified.guide walkthrough\n\ncreate an (Administrator) IAM user with the AdministratorAccess policy or with another policy that permits the user to access the private S3 bucket created above\ncreate access keys for the IAM user\ncopy the Access key ID and Secret Access Key into ~/.aws/credentials"
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "Multi-Step Dev Containers Workflow",
    "section": "",
    "text": "Clone this repo into the working folder (eg. clone into ~/Downloads) and launch VS Code.\n\n\nUse the following approach to execute a single step of the workflow (01-get-data or 02-eda) inside a container. If the container has not been built, it will first be built before running it.\n\nSelect File &gt; Open Folder… and select the notebooks sub-folder (eg. select ~/Downloads/devcontainer-notebooks/notebooks)\n\ntwo sub-folders (01-get-data and 02-eda) should be visible\neach sub-folder corresponds to a single step in the above workflow\n\nDuring the first build and run of a container, a pop-up appears at the bottom right of the screen indicating the parent directory is detected to be a git repository. It asks if this repository should be opened in the text editor (VS Code)\n\nA git repository was found in the parent folders of the workspace or the open file(s). Would you like to open the repository?\n\nThe parent directory is not required for any analysis inside the container, so this message can be ignored. Click Never.\nPress F1 or Ctrl + Shift + P and select Dev Containers: Open Folder in Container….\nSelect a sub-folder (01-get-data or 02-eda) to run one step of the workflow\n\na container will now be built to run this step\n\n(optional) A pop-up appears at the bottom right of the screen indicating Starting Dev Contiainer (show log). Click Starting Dev Contiainer (show log) to view the container build logs.\n(optional) The TERMINAL shows the logs of the container build process. To view these logs, select TERMINAL &gt; Maximize Panel Size.\n(optional) After the container has been built\n\nthe logs in the TERMINAL will stop updating\nthe lower left remote indicator will display one of\n\nDev Container: Get Data (for the get-data step of the workflow)\nDev Container: Eda (for the eda step)\n\nthe following contents of the workspace will be visible in the File Explorer\n\n.devcontainer\nnotebooks\nsrc\n\n\n(optional) In the terminal, click Restore Panel Size.\nOpen the notebooks folder and launch a notebook\nSelect a Jupyter kernel\n\nfrom the top-right corner, click Select Kernel\n\nselect Python Environments\nselect one of\n\nget-data (Python 3.xx.xx)\neda (Python 3.xx.xx)\n\n\nall the Python libraries listed in the above .devcontainer/environment.yml file for development of this step of the workflow have been installed in this Python environment. After the kernel is selected, all these libraries can be imported into this notebook and all cells in the notebook can be executed without any errors about missing dependencies.\n\n\n\n\n\n\nShut down the container inside which the notebook for the workflow step is running\n\nclose any open notebooks\nclose the connection to the container\n\nclick the lower left remote development indicator\nselect Close Remote Connection\n\n\n\n\n\n\nTo run a container that was previously built locally, follow steps 1 to 9 from above.\n\n\n\n\nRemove any container resources for the workflow step\n\nlaunch a terminal at the root directory of the project (eg. in ~/Downloads)\nclean up containers and images for a single workflow step (get-data or eda)\n ~/Downloads/devcontainer-notebooks$ make reset-&lt;step-name&gt;\n(optional) Remove unused docker resources\n~/Downloads/devcontainer-notebooks$ make docker-system-prune"
  },
  {
    "objectID": "index.html#notes",
    "href": "index.html#notes",
    "title": "Multi-Step Dev Containers Workflow",
    "section": "",
    "text": "Code formatting settings specified in .devcontainer/devcontainers.json are being ignored. As a result, Python modules in src are not correctly formatted.\nThis container will support running a Jupyter notebook in VS Code. It will not start the Jupyter Lab interface in a web browser.\nIt was not possible to mount the local ~/.aws folder to the same path inside the container using the docker-compose.yml file. Instead, this mounting was done using the devcontainer.json file.\nThis is an opinionated setup to work with containers inside multiple containers. A separate docker-compose.yml file is used per step of the workflow. An alternate setup to work with multiple Dev Containers (not involving notebooks) is demonstrated here. It has the benefit of using a single docker-compose.yml file that could be adapted to capture all steps of a multi-step notebook-based workflow."
  },
  {
    "objectID": "index.html#links-used",
    "href": "index.html#links-used",
    "title": "Multi-Step Dev Containers Workflow",
    "section": "",
    "text": "AWS documentation to create an IAM user\nVS Code\n\nConfiguring multiple Dev Containers\nDev Containers Playlist\n\nchange a user\nwork with monorepos\nadd (mount) a local folder"
  }
]